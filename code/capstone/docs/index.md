# Capstone Project Documentation

Welcome to the documentation for the Autonomous Humanoid Capstone Project.

This documentation provides a detailed overview of the project's architecture, components, and setup instructions.

## Project Goal

The primary goal of this project is to create an end-to-end robotic system that can understand and act upon spoken human commands. The robot, operating in a simulated environment, will be able to perform tasks such as fetching objects from different locations.

## Key Features

-   **Voice-Powered**: Uses OpenAI's Whisper for robust speech recognition.
-   **LLM-Driven**: Leverages a Large Language Model for intelligent task planning.
-   **ROS 2 Based**: Built on the industry-standard Robot Operating System (ROS 2).
-   **Modular and Extensible**: Designed with a clear separation of concerns to allow for future expansion.

## Documentation Sections

-   **[Architecture](./architecture.md)**: A deep dive into the system's design and how the different components interact.
-   **[Setup Guide](./setup_guide.md)**: Detailed instructions for setting up the environment and running the project.
